{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2fd9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 102,450 names from names_group3.txt\n",
      "Vocabulary size: 27 characters\n",
      "   Characters: abcdefghijklmnopqrstuvwxyz\n",
      "Dataset splits:\n",
      "   Train: 81,960 names (80%)\n",
      "   Val:   10,245 names (10%)\n",
      "   Test:  10,245 names (10%)\n",
      "\n",
      "==================================================\n",
      "DATASET STATISTICS\n",
      "==================================================\n",
      "Total names:    102,450\n",
      "Train names:    81,960\n",
      "Val names:      10,245\n",
      "Test names:     10,245\n",
      "Vocabulary:     27 characters\n",
      "Name length:    min=2, max=15, avg=6.5\n",
      "==================================================\n",
      "\n",
      "\n",
      "Test encoding/decoding:\n",
      "Original: emma\n",
      "Encoded:  [5, 13, 13, 1]\n",
      "Decoded:  emma\n",
      "\n",
      "First 10 train names: ['makenzie', 'seti', 'topeka', 'mianicole', 'summerlynn', 'basha', 'stevyn', 'wilferd', 'swindell', 'zilla']\n",
      "\n",
      "Vocabulary: .abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_utils import load_dataset\n",
    "\n",
    "# Load your data\n",
    "dataset = load_dataset('../data/processed/names_group3.txt')\n",
    "\n",
    "# Test encoding/decoding\n",
    "test_name = \"emma\"\n",
    "encoded = dataset.encode(test_name)\n",
    "decoded = dataset.decode(encoded)\n",
    "\n",
    "print(f\"\\nTest encoding/decoding:\")\n",
    "print(f\"Original: {test_name}\")\n",
    "print(f\"Encoded:  {encoded}\")\n",
    "print(f\"Decoded:  {decoded}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nFirst 10 train names: {dataset.train_names[:10]}\")\n",
    "print(f\"\\nVocabulary: {''.join(dataset.chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b318e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: valerie\n",
      "Encoded:  [22, 1, 12, 5, 18, 9, 5]\n",
      "Decoded:  valerie\n",
      "\n",
      "Character mapping:\n",
      "  'v' -> 22\n",
      "  'a' -> 1\n",
      "  'l' -> 12\n",
      "  'e' -> 5\n",
      "  'r' -> 18\n",
      "  'i' -> 9\n",
      "  'e' -> 5\n"
     ]
    }
   ],
   "source": [
    "# Test encoding/decoding\n",
    "test_name = \"valerie\"\n",
    "encoded = dataset.encode(test_name)\n",
    "decoded = dataset.decode(encoded)\n",
    "\n",
    "print(f\"Original: {test_name}\")\n",
    "print(f\"Encoded:  {encoded}\")\n",
    "print(f\"Decoded:  {decoded}\")\n",
    "print(f\"\\nCharacter mapping:\")\n",
    "for char, idx in zip(test_name, encoded):\n",
    "    print(f\"  '{char}' -> {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ca7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example names from each split:\n",
      "\n",
      "Train: ['makenzie', 'seti', 'topeka', 'mianicole', 'summerlynn', 'basha', 'stevyn', 'wilferd', 'swindell', 'zilla']\n",
      "Val:   ['arayah', 'mikhaela', 'idalyz', 'juliyan', 'richey', 'eimaan', 'kamille', 'fayza', 'adileny', 'faviola']\n",
      "Test:  ['annahi', 'javare', 'riti', 'jasaun', 'kadeesha', 'ketisha', 'marquina', 'laylani', 'dharmesh', 'nakul']\n"
     ]
    }
   ],
   "source": [
    "# Show some example names from each split\n",
    "print(\"Example names from each split:\")\n",
    "print(f\"\\nTrain: {dataset.train_names[:10]}\")\n",
    "print(f\"Val:   {dataset.val_names[:10]}\")\n",
    "print(f\"Test:  {dataset.test_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27571c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full vocabulary:\n",
      "Characters: ['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "String-to-Index (first 10):\n",
      "  '.' -> 0\n",
      "  'a' -> 1\n",
      "  'b' -> 2\n",
      "  'c' -> 3\n",
      "  'd' -> 4\n",
      "  'e' -> 5\n",
      "  'f' -> 6\n",
      "  'g' -> 7\n",
      "  'h' -> 8\n",
      "  'i' -> 9\n"
     ]
    }
   ],
   "source": [
    "# See the full vocabulary\n",
    "print(\"Full vocabulary:\")\n",
    "print(f\"Characters: {dataset.chars}\")\n",
    "print(f\"\\nString-to-Index (first 10):\")\n",
    "for i, (ch, idx) in enumerate(dataset.stoi.items()):\n",
    "    if i < 10:\n",
    "        print(f\"  '{ch}' -> {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d51f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
